{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aware-racing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
      "tensorflow 2.4.0\n",
      "matplotlib 3.3.3\n",
      "numpy 1.19.2\n",
      "pandas 1.1.5\n",
      "sklearn 0.24.0\n",
      "tensorflow 2.4.0\n",
      "tensorflow.keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import sklearn\n",
    "import PIL.Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (12, 12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in tf, mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "established-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU configurations\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.allow_soft_placement=True\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-snake",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "willing-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename files\n",
    "# Run this cell only once or when there are new data added to the folder\n",
    "models_path = \"D:\\\\datasets\\\\theme-classification\\\\models\\\\\"\n",
    "patterns_path = \"D:\\\\datasets\\\\theme-classification\\\\patterns\\\\\"\n",
    "\n",
    "def rename_files(path, cwd):\n",
    "    os.chdir(path)\n",
    "    for old_filename in os.listdir(path):\n",
    "        new_filename = deepcopy(old_filename)\n",
    "        if ' ' in old_filename:\n",
    "            new_filename = '_'.join(old_filename.split())\n",
    "        if \"条纹\" in old_filename:\n",
    "            new_filename = \"stride\".join(new_filename.split(\"条纹\"))\n",
    "        if \"格子\" in old_filename:\n",
    "            new_filename = \"grid\".join(new_filename.split(\"格子\"))\n",
    "        if \"几何图形\" in old_filename:\n",
    "            new_filename = \"geometry\".join(new_filename.split(\"几何图形\"))\n",
    "        if new_filename != old_filename:\n",
    "            print(new_filename)\n",
    "            os.rename(old_filename, new_filename)\n",
    "    os.chdir(cwd)\n",
    "\n",
    "current_path = os.getcwd()\n",
    "# rename_files(models_path, current_path)\n",
    "# rename_files(patterns_path, current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "strong-texas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old = \"aaaz\"\n",
    "new = \"aaaz\"\n",
    "\n",
    "new == old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "impressed-princeton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdsadstrideasdasdsadas'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'stride'.join(\"asdsad条纹asdasdsadas\".split(\"条纹\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "amazing-victor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function nt.rename(src, dst, *, src_dir_fd=None, dst_dir_fd=None)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "experienced-checklist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"好\" in \"好的\"\n",
    "' ' in \" a  a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "casual-second",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6336\n",
      "2007\n"
     ]
    }
   ],
   "source": [
    "models_path = \"D:\\\\datasets\\\\theme-classification\\\\models\\\\\"\n",
    "patterns_path = \"D:\\\\datasets\\\\theme-classification\\\\patterns\\\\\"\n",
    "\n",
    "print(len(os.listdir(models_path)))\n",
    "print(len(os.listdir(patterns_path)))\n",
    "\n",
    "models_filelist = os.listdir(models_path)\n",
    "patterns_filelist = os.listdir(patterns_path)\n",
    "\n",
    "def fullpath(filelist, folderpath):\n",
    "    return [folderpath + filename for filename in filelist]\n",
    "\n",
    "models_filelist = fullpath(models_filelist, models_path)\n",
    "\n",
    "models_count = len(models_filelist)\n",
    "patterns_count = len(patterns_filelist)\n",
    "\n",
    "# # Shuffle the datasets\n",
    "# random.seed(1)\n",
    "# random.shuffle(models_filelist)\n",
    "# random.shuffle(patterns_filelist)\n",
    "\n",
    "# # Construct dataframes from data\n",
    "# models_df = pd.DataFrame(models_filelist)\n",
    "# patterns_df = pd.DataFrame(patterns_filelist)\n",
    "\n",
    "# Choose 90% as training set, 10% as validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-limit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "agreed-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.columns = [\"filepath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "alive-deployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1607929334de57ab8ec9979776545065005788df23.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16021206240932833f4cf7e1f1e414b27884d8d3d3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610943912838140758e4713b29514f7b8bdb2b0e4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOVF-WD2488_V1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160983489694fe9e4a35457b4dc9b5b37b7e4140ab.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>16073190387ba883c281f968b072dae9c8a45636bb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>15952103004a53be17d528cc9e78b10bf03f4eebc7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>VBRD-WD5_V1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>BGEN-WD871_V1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>16055150308c70e9c69b091a6f801a3e2f6f5ef3f0.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6336 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath\n",
       "0     1607929334de57ab8ec9979776545065005788df23.jpg\n",
       "1     16021206240932833f4cf7e1f1e414b27884d8d3d3.jpg\n",
       "2     1610943912838140758e4713b29514f7b8bdb2b0e4.jpg\n",
       "3                                 LOVF-WD2488_V1.jpg\n",
       "4     160983489694fe9e4a35457b4dc9b5b37b7e4140ab.jpg\n",
       "...                                              ...\n",
       "6331  16073190387ba883c281f968b072dae9c8a45636bb.jpg\n",
       "6332  15952103004a53be17d528cc9e78b10bf03f4eebc7.jpg\n",
       "6333                                 VBRD-WD5_V1.jpg\n",
       "6334                               BGEN-WD871_V1.jpg\n",
       "6335  16055150308c70e9c69b091a6f801a3e2f6f5ef3f0.jpg\n",
       "\n",
       "[6336 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "empirical-swift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "633"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(models_count * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "following-exhaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function list.append>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[].append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hydraulic-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(patterns_count * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "agricultural-native",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1607929334de57ab8ec9979776545065005788df23.jpg',\n",
       " '16021206240932833f4cf7e1f1e414b27884d8d3d3.jpg',\n",
       " '1610943912838140758e4713b29514f7b8bdb2b0e4.jpg',\n",
       " 'LOVF-WD2488_V1.jpg',\n",
       " '160983489694fe9e4a35457b4dc9b5b37b7e4140ab.jpg',\n",
       " 'VCHP-WD23_V1.jpg',\n",
       " '160756301600d4a49d81f7dd7cd6b16961a88525e8.jpg',\n",
       " '1608717428530b1ed23ec34302e7382ca115057e50.jpg',\n",
       " '16104309408668086d26cb8c358ef8807e698c4e07.jpg',\n",
       " 'CILL-WD281_V3.jpg']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_filelist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "reliable-castle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['185604-preview-small.jpg',\n",
       " '23_几何图形_6786.png',\n",
       " '186094-preview-small.jpg',\n",
       " '186056-preview-small.jpg',\n",
       " '23_几何图形_57.png',\n",
       " '186232-preview-small.jpg',\n",
       " '185764-preview-small.jpg',\n",
       " '23_几何图形_4931.png',\n",
       " '23_几何图形_2186.png',\n",
       " '185700-preview-small.jpg']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns_filelist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abstract-accused",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Random.shuffle of <random.Random object at 0x000001FC82261EF8>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-lighter",
   "metadata": {},
   "source": [
    "## Modeling with ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-tamil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_fine_tune = keras.models.Sequential()\n",
    "resnet50_fine_tune.add(keras.applications.ResNet50(include_top=False, weights='imagenet', pooling='avg'))\n",
    "resnet50_fine_tune.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "resnet50_fine_tune.layers[0].trainable = False  # set ResNet (regarded as one layer)\n",
    "\n",
    "resnet50_fine_tune.compile(loss=\"categorical_crossentropy\",\n",
    "                           optimizer=\"rmsprop\",\n",
    "                           metrics=[\"accuracy\"])\n",
    "resnet50_fine_tune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-water",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-beauty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-chrome",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
