{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "static-issue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
      "tensorflow 2.4.0\n",
      "matplotlib 3.3.3\n",
      "numpy 1.19.2\n",
      "pandas 1.1.5\n",
      "sklearn 0.24.0\n",
      "tensorflow 2.4.0\n",
      "tensorflow.keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import sklearn\n",
    "import PIL.Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (12, 12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in tf, mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "mechanical-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent error：image file is truncated (# bytes not processed)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "parallel-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU configurations\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.allow_soft_placement=True\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-steel",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "increasing-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename files\n",
    "# Run this cell only once or when there are new data added to the folder\n",
    "models_path = \"D:\\\\datasets\\\\theme-classification\\\\models\\\\\"\n",
    "patterns_path = \"D:\\\\datasets\\\\theme-classification\\\\patterns\\\\\"\n",
    "\n",
    "def rename_files(path, cwd):\n",
    "    os.chdir(path)\n",
    "    for old_filename in os.listdir(path):\n",
    "        new_filename = deepcopy(old_filename)\n",
    "        if ' ' in old_filename:\n",
    "            new_filename = '_'.join(old_filename.split())\n",
    "        if \"条纹\" in old_filename:\n",
    "            new_filename = \"stride\".join(new_filename.split(\"条纹\"))\n",
    "        if \"格子\" in old_filename:\n",
    "            new_filename = \"grid\".join(new_filename.split(\"格子\"))\n",
    "        if \"几何图形\" in old_filename:\n",
    "            new_filename = \"geometry\".join(new_filename.split(\"几何图形\"))\n",
    "        if new_filename != old_filename:\n",
    "            print(new_filename)\n",
    "            os.rename(old_filename, new_filename)\n",
    "    os.chdir(cwd)\n",
    "\n",
    "current_path = os.getcwd()\n",
    "# Uncomment those to rename filenames\n",
    "# rename_files(models_path, current_path)\n",
    "# rename_files(patterns_path, current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "coated-thailand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model count:  6336\n",
      "pattern count:  2003\n",
      "training set size:  7504\n",
      "validation set size:  835\n"
     ]
    }
   ],
   "source": [
    "models_path = \"D:\\\\datasets\\\\theme-classification\\\\models\\\\\"\n",
    "patterns_path = \"D:\\\\datasets\\\\theme-classification\\\\patterns\\\\\"\n",
    "\n",
    "print(\"model count: \", len(os.listdir(models_path)))\n",
    "print(\"pattern count: \", len(os.listdir(patterns_path)))\n",
    "\n",
    "models_filelist = os.listdir(models_path)\n",
    "patterns_filelist = os.listdir(patterns_path)\n",
    "\n",
    "def fullpath(filelist, folderpath):\n",
    "    return [folderpath + filename for filename in filelist]\n",
    "\n",
    "models_filelist = fullpath(models_filelist, models_path)\n",
    "patterns_filelist = fullpath(patterns_filelist, patterns_path)\n",
    "\n",
    "models_count = len(models_filelist)\n",
    "patterns_count = len(patterns_filelist)\n",
    "\n",
    "# # Shuffle the datasets\n",
    "random.seed(1)\n",
    "random.shuffle(models_filelist)\n",
    "random.shuffle(patterns_filelist)\n",
    "\n",
    "# Generate labels\n",
    "def generate_labels(filelist, label):\n",
    "    return [(filename, label) for filename in filelist]\n",
    "\n",
    "models_filelist = generate_labels(models_filelist, \"model\")\n",
    "patterns_filelist = generate_labels(patterns_filelist, \"pattern\")\n",
    "\n",
    "# Construct training set and validation set\n",
    "training_filelist = models_filelist[:int(models_count*0.9)] + patterns_filelist[:int(patterns_count*0.9)]\n",
    "validation_filelist = models_filelist[int(models_count*0.9):] + patterns_filelist[int(patterns_count*0.9):]\n",
    "random.shuffle(training_filelist)\n",
    "random.shuffle(validation_filelist)\n",
    "\n",
    "# # Construct dataframes from data\n",
    "# models_df = pd.DataFrame(models_filelist)\n",
    "# patterns_df = pd.DataFrame(patterns_filelist)\n",
    "# models_df.columns = [\"filepath\", \"class\"]\n",
    "# patterns_df.columns = [\"filepath\", \"class\"]\n",
    "\n",
    "training_df = pd.DataFrame(training_filelist)\n",
    "validation_df = pd.DataFrame(validation_filelist)\n",
    "training_df.columns = [\"filepath\", \"class\"]\n",
    "validation_df.columns = [\"filepath\", \"class\"]\n",
    "\n",
    "print(\"training set size: \", len(training_filelist))\n",
    "print(\"validation set size: \", len(validation_filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "latin-standard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\datasets\\theme-classification\\models\\PARR-W...</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\datasets\\theme-classification\\models\\160897...</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\datasets\\theme-classification\\patterns\\1854...</td>\n",
       "      <td>pattern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\datasets\\theme-classification\\models\\160878...</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\datasets\\theme-classification\\models\\160913...</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath    class\n",
       "0  D:\\datasets\\theme-classification\\models\\PARR-W...    model\n",
       "1  D:\\datasets\\theme-classification\\models\\160897...    model\n",
       "2  D:\\datasets\\theme-classification\\patterns\\1854...  pattern\n",
       "3  D:\\datasets\\theme-classification\\models\\160878...    model\n",
       "4  D:\\datasets\\theme-classification\\models\\160913...    model"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-pixel",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "arctic-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7504 non-validated image filenames belonging to 2 classes.\n",
      "Found 835 non-validated image filenames belonging to 2 classes.\n",
      "7504 835\n"
     ]
    }
   ],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "batch_size = 32\n",
    "num_classes = 1\n",
    "class_names = ['model', 'pattern']\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = keras.applications.resnet50.preprocess_input,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,   # percentage\n",
    "    height_shift_range = 0.2,  # percentage\n",
    "    shear_range = 0.2,         # shear strength\n",
    "    zoom_range = 0.2,          # zoom strength\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"wrap\"\n",
    ")\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    training_df,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'class',\n",
    "    classes = class_names,\n",
    "    target_size = (height, width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 7,\n",
    "    shuffle = True,\n",
    "    class_mode = 'sparse',\n",
    "    validate_filenames = False,\n",
    ")\n",
    "\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = keras.applications.resnet50.preprocess_input\n",
    ")\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    validation_df,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'class',\n",
    "    classes = class_names,\n",
    "    target_size = (height, width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 7,\n",
    "    shuffle = False,\n",
    "    class_mode = 'sparse',\n",
    "    validate_filenames = False,\n",
    ")\n",
    "\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples\n",
    "print(train_num, valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "continental-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "formed-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3) (32,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    x, y = train_generator.next()\n",
    "    print(x.shape, y.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-ensemble",
   "metadata": {},
   "source": [
    "## Modeling with ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "intended-europe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50_fine_tune = keras.models.Sequential()\n",
    "resnet50_fine_tune.add(keras.applications.ResNet50(include_top=False, weights='imagenet', pooling='avg'))\n",
    "resnet50_fine_tune.add(keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "resnet50_fine_tune.layers[0].trainable = False  # set ResNet (regarded as one layer)\n",
    "\n",
    "resnet50_fine_tune.compile(loss=\"binary_crossentropy\",\n",
    "                           optimizer=\"adam\",\n",
    "                           metrics=[\"accuracy\"])\n",
    "resnet50_fine_tune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "orange-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 234s 956ms/step - loss: 0.1437 - accuracy: 0.9313 - val_loss: 0.0146 - val_accuracy: 0.9940\n"
     ]
    }
   ],
   "source": [
    "epochs = 1  # 10 for fine tune!\n",
    "history = resnet50_fine_tune.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = train_num // batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = valid_generator,\n",
    "    validation_steps = valid_num // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "behavioral-holly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 224, 224, 3)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "regulation-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1. if out >= 0.5 else 0. for out in resnet50_fine_tune.predict_on_batch(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "upper-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "polar-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = valid_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "entitled-beverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "previous-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1. if out >= 0.5 else 0. for out in resnet50_fine_tune.predict_on_batch(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "weekly-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "limited-airfare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved-models/theme-classi-resnet50.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./saved-models\"):\n",
    "    os.mkdir(\"./saved-models\")\n",
    "\n",
    "resnet50_fine_tune.save(filepath='./saved-models/theme-classi-resnet50.tf',\n",
    "                        include_optimizer=True,\n",
    "                        save_format = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-member",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
