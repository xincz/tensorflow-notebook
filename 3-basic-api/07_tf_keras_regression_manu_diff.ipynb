{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T05:48:22.769257Z",
     "start_time": "2020-11-30T05:48:20.059517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.3.2\n",
      "numpy 1.18.4\n",
      "pandas 1.1.4\n",
      "sklearn 0.23.2\n",
      "tensorflow 2.3.1\n",
      "tensorflow.keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T05:51:46.358248Z",
     "start_time": "2020-11-30T05:50:06.607860Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T05:59:06.686826Z",
     "start_time": "2020-11-30T05:59:06.666300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain_all, xtest, ytrain_all, ytest = train_test_split(\n",
    "    housing.data, housing.target, random_state=7)\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(\n",
    "    xtrain_all ,ytrain_all, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:29:31.699188Z",
     "start_time": "2020-11-30T06:29:31.684187Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "xtrain_scaled = scaler.fit_transform(xtrain)\n",
    "xvalid_scaled= scaler.transform(xvalid)\n",
    "xtest_scaled = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Use metrics\n",
    "# Cumulative!\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "print(metric([5.], [2.]))\n",
    "print(metric([0.], [1.]))\n",
    "print(metric.result())\n",
    "metric.reset_states()\n",
    "print(metric([5.], [3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:29:33.139973Z",
     "start_time": "2020-11-30T06:29:33.069970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  train mse: 0.94064534\t valid mse:  0.8777602265662375\n",
      "Epoch 1  train mse: 0.70031184\t valid mse:  0.7682967837523749in mse: 0.6009069 1  train mse: 0.5825403 1  train mse: 0.5731136\n",
      "Epoch 2  train mse: 0.7010485\t valid mse:  0.471908772657568761 2  train mse: 1.063051 2  train mse: 0.8626429 2  train mse: 0.79456896 2  train mse: 0.7522588 2  train mse: 0.7183713\n",
      "Epoch 3  train mse: 0.43302885\t valid mse:  0.4538411630387052mse: 0.44908574 3  train mse: 0.44832596 3  train mse: 0.44886678 3  train mse: 0.43700093  train mse: 0.4370341\n",
      "Epoch 4  train mse: 0.409268\t valid mse:  0.427472216249318ain mse: 0.3922178 4  train mse: 0.3941072 4  train mse: 0.41189796 4  train mse: 0.40647456 4  train mse: 0.40586767\n",
      "Epoch 5  train mse: 0.41166383\t valid mse:  0.41646038089221876n mse: 0.40852377 5  train mse: 0.41114926 train mse: 0.41024688 5  train mse: 0.4113097\n",
      "Epoch 6  train mse: 0.403454\t valid mse:  0.4280744200012577rain mse: 0.37988552 6  train mse: 0.40863234 6  train mse: 0.38817146 6  train mse: 0.3993288 6  train mse: 0.39459962 6  train mse: 0.40166792\n",
      "Epoch 7  train mse: 0.37457338\t valid mse:  0.4040678848491842n mse: 0.34622017 7  train mse: 0.36784512 7  train mse: 0.37524948 7  train mse: 0.37491056\n",
      "Epoch 8  train mse: 0.36540464\t valid mse:  0.3955201245439597in mse: 0.371153628  train mse: 0.364966728  train mse: 0.36686516 8  train mse: 0.3636425 8  train mse: 0.3638066\n",
      "Epoch 9  train mse: 0.37568676\t valid mse:  0.39868164843283241 9  train mse: 0.37087387 9  train mse: 0.36988574 9  train mse: 0.37232682 9  train mse: 0.3777636 9  train mse: 0.376223\n",
      "Epoch 10  train mse: 0.36767384\t valid mse:  0.3822934313404142rain mse: 0.3675646 10  train mse: 0.3666584 10  train mse: 0.36899203 0.36798942\n",
      "Epoch 11  train mse: 0.3682237\t valid mse:  0.39251041358406386rain mse: 0.38157684 11  train mse: 0.3807828 11  train mse: 0.37615392 11  train mse: 0.3765589 11  train mse: 0.37495664\n",
      "Epoch 12  train mse: 0.36122373\t valid mse:  0.3774111791841005rain mse: 0.34679395 12  train mse: 0.3652250512  train mse: 0.35981822 12  train mse: 0.35531852 12  train mse: 0.35974005 12  train mse: 0.35827252 12  train mse: 0.35866642 12  train mse: 0.36080995\n",
      "Epoch 13  train mse: 0.39273334\t valid mse:  0.37224660638039564ain mse: 0.3689281 13  train mse: 0.40573573 13  train mse: 0.40588883 13  train mse: 0.39497277 13  train mse: 0.395154420.38894445 13  train mse: 0.39327663\n",
      "Epoch 14  train mse: 0.3761485\t valid mse:  0.373305145033990654372 14  train mse: 0.3689278 train mse: 0.3682786 14  train mse: 0.38057047 14  train mse: 0.37909922\n",
      "Epoch 15  train mse: 0.36891896\t valid mse:  0.3687459616927216n mse: 0.35295328 15  train mse: 0.35305548\n",
      "Epoch 16  train mse: 0.3691286\t valid mse:  0.37153483473871035\n",
      "Epoch 17  train mse: 0.3434473\t valid mse:  0.37204433638850026rain mse: 0.3524891\n",
      "Epoch 18  train mse: 0.35412514\t valid mse:  0.36415499160613607ain mse: 0.36315626 18  train mse: 0.35593623 18  train mse: 0.35456446 18  train mse: 0.35579756\n",
      "Epoch 19  train mse: 0.3468457\t valid mse:  0.36848082372917357rain mse: 0.3732464 19  train mse: 0.36792645 19  train mse: 0.35846812 19  train mse: 0.34945923 19  train mse: 0.3461932 19  train mse: 0.34698856 19  train mse: 0.34299502 19  train mse: 0.34612647 19  train mse: 0.34355828\n",
      "Epoch 20  train mse: 0.35820946\t valid mse:  0.3654325142310907rain mse: 0.36679912 20  train mse: 0.36213824 20  train mse: 0.36671114 20  train mse: 0.36345664 20  train mse: 0.35727912 20  train mse: 0.35495684\n",
      "Epoch 21  train mse: 0.35475677\t valid mse:  0.3801755900259848220621  train mse: 0.33977145 21  train mse: 0.35473737 21  train mse: 0.35643256 21  train mse: 0.35384262 21  train mse: 0.35675707\n",
      "Epoch 22  train mse: 0.34837884\t valid mse:  0.36911154568634114 mse: 0.34788948 22  train mse: 0.33539197 22  train mse: 0.33460668 22  train mse: 0.33511293 22  train mse: 0.33168748 22  train mse: 0.34924632\n",
      "Epoch 23  train mse: 0.35233682\t valid mse:  0.3604409137600433rain mse: 0.3388155 23  train mse: 0.3513805 23  train mse: 0.34869233 23  train mse: 0.34778115 23  train mse: 0.34991747 23  train mse: 0.35049447\n",
      "Epoch 24  train mse: 0.34246713 24  train mse: 0.3293986 24  train mse: 0.33709896 24  train mse: 0.31421146 24  train mse: 0.32898608 24  train mse: 0.33547762 24  train mse: 0.33817497 24  train mse: 0.3442660624  train mse: 0.34382382\t valid mse:  0.35775169258379413\n",
      "Epoch 25  train mse: 3.2806554\t valid mse:  2.77244815149034724077 25  train mse: 0.32355607\n",
      "Epoch 26  train mse: 0.52360874\t valid mse:  0.46625443342649747in mse: 0.5879065\n",
      "Epoch 27  train mse: 0.40857553\t valid mse:  0.4145824190406461rain mse: 0.41550404 27  train mse: 0.41969138 27  train mse: 0.4219876 27  train mse: 0.41311806 27  train mse: 0.40858588 train mse: 0.40837952\n",
      "Epoch 28  train mse: 0.4387605\t valid mse:  0.39359865825636414 mse: 0.43478894 28  train mse: 0.45050934 28  train mse: 0.44707772 28  train mse: 0.43664607 28  train mse: 0.46559066 28  train mse: 0.45607498 28  train mse: 0.44325778\n",
      "Epoch 29  train mse: 0.37804583\t valid mse:  0.38451408982250523mse: 0.43883976 29  train mse: 0.41058865 29  train mse: 0.38936663 29  train mse: 0.38695794 29  train mse: 0.38853633 29  train mse: 0.3881144 29  train mse: 0.37825558\n",
      "Epoch 30  train mse: 0.38146108\t valid mse:  0.3817548953168587rain mse: 0.41677338 30  train mse: 0.38566843\n",
      "Epoch 31  train mse: 0.3651775\t valid mse:  0.37140143117423025ain mse: 0.37562802  train mse: 0.36819142 0.37457845  train mse: 0.36909306 31  train mse: 0.36669484\n",
      "Epoch 32  train mse: 0.45098147\t valid mse:  13.828197927998014\n",
      "Epoch 33  train mse: 0.55224705\t valid mse:  0.3833020374748114\n",
      "Epoch 34  train mse: 0.34952688\t valid mse:  0.379248317328369170943\n",
      "Epoch 35  train mse: 0.35156164\t valid mse:  0.37481221954608784\n",
      "Epoch 36  train mse: 0.3506583\t valid mse:  0.3700170560128273rain mse: 0.3658143 36  train mse: 0.35691786 36  train mse: 0.34686348\n",
      "Epoch 37  train mse: 0.34793362\t valid mse:  0.36625634685664443ain mse: 0.341174 37  train mse: 0.34507632 37  train mse: 0.34905848\n",
      "Epoch 38  train mse: 0.3359148\t valid mse:  0.3664201360488511train mse: 0.33829096\n",
      "Epoch 39  train mse: 0.33336353\t valid mse:  0.3624802171364249\n",
      "Epoch 40  train mse: 0.33965626\t valid mse:  0.3591398469471514\n",
      "Epoch 41  train mse: 0.34324175\t valid mse:  0.3600276913003724\n",
      "Epoch 42  train mse: 0.32676634\t valid mse:  0.358215733876324156354\n",
      "Epoch 43  train mse: 0.34410173\t valid mse:  0.35899930187400303\n",
      "Epoch 44  train mse: 0.33060524\t valid mse:  0.35488592161781407 mse: 0.3327193 44  train mse: 0.3398835\n",
      "Epoch 45  train mse: 0.34197348\t valid mse:  0.35001083311750253in mse: 0.34183666\n",
      "Epoch 46  train mse: 0.33477688\t valid mse:  0.3537532963124128\n",
      "Epoch 47  train mse: 0.33848187\t valid mse:  0.3504043077730694ain mse: 0.33575523 47  train mse: 0.3354998\n",
      "Epoch 48  train mse: 0.35143134\t valid mse:  0.5004831809803852rain mse: 0.34913635\n",
      "Epoch 49  train mse: 0.33912528\t valid mse:  0.3506693700839855rain mse: 0.3422831\n",
      "Epoch 50  train mse: 0.32897556\t valid mse:  0.3502566491836436rain mse: 0.3202661 50  train mse: 0.32474205\n",
      "Epoch 51  train mse: 0.3266754\t valid mse:  0.34611924893524715rain mse: 0.33386296 51  train mse: 0.33473477\n",
      "Epoch 52  train mse: 0.33580843\t valid mse:  0.3481287081281783ain mse: 0.3364881\n",
      "Epoch 53  train mse: 0.33254993\t valid mse:  0.3545292543333164 mse: 0.3423002\n",
      "Epoch 54  train mse: 0.42513806\t valid mse:  3.7639602526939244\n",
      "Epoch 55  train mse: 0.3990637\t valid mse:  0.36064416045673514\n",
      "Epoch 56  train mse: 0.33942226\t valid mse:  0.36608210857806095\n",
      "Epoch 57  train mse: 0.33458078\t valid mse:  0.35483381912871803\n",
      "Epoch 58  train mse: 0.33881882\t valid mse:  0.3529254640174745\n",
      "Epoch 59  train mse: 0.35159248\t valid mse:  0.352762356087568train mse: 0.3181133359  train mse: 0.3338141 59  train mse: 0.33308396 59  train mse: 0.3539375\n",
      "Epoch 60  train mse: 0.32433036\t valid mse:  0.354998926079850731986 60  train mse: 0.35852537 train mse: 0.33890116 60  train mse: 0.33626062 60  train mse: 0.33183372 60  train mse: 0.3281608\n",
      "Epoch 61  train mse: 0.33242932\t valid mse:  0.5262557512821143rain mse: 0.34102464 61  train mse: 0.3397977 61  train mse: 0.33346692 61  train mse: 0.3294308 61  train mse: 0.32256305\n",
      "Epoch 62  train mse: 0.33082685\t valid mse:  0.35382593574866117ain mse: 0.34596798 62  train mse: 0.327765  train mse: 0.32993254 62  train mse: 0.3306123 62  train mse: 0.33075684\n",
      "Epoch 63  train mse: 0.3099914\t valid mse:  0.352050157428546 train mse: 0.31034306 63  train mse: 0.30669174 63  train mse: 0.30637196 63  train mse: 0.3116063 63  train mse: 0.3143935  train mse: 0.31347373 63  train mse: 0.31330723\n",
      "Epoch 64  train mse: 0.3274918\t valid mse:  0.3600684833677968train mse: 0.31711817 64  train mse: 0.3280953 0.324265120.32690609 64  train mse: 0.32352796 64  train mse: 0.32637665\n",
      "Epoch 65  train mse: 0.32184613\t valid mse:  0.3488858147872041rain mse: 0.31881925  train mse: 0.32265648 65  train mse: 0.32439393 65  train mse: 0.3223227\n",
      "Epoch 66  train mse: 0.32936352\t valid mse:  0.34701363915446065402 66  train mse: 0.3341869 66  train mse: 0.3314413 66  train mse: 0.33704072 66  train mse: 0.33687937 train mse: 0.33531436 66  train mse: 0.32929662 66  train mse: 0.33164537\n",
      "Epoch 67  train mse: 0.3157945\t valid mse:  0.343736771266681rain mse: 0.3297925 0.32516262 67  train mse: 0.32008302 67  train mse: 0.32466277 67  train mse: 0.32074976  train mse: 0.32190883 67  train mse: 0.31496274\n",
      "Epoch 68  train mse: 0.3261337\t valid mse:  0.3441372471000677train mse: 0.32492697 68  train mse: 0.3280466 68  train mse: 0.32373095 68  train mse: 0.3285383 68  train mse: 0.33031568 68  train mse: 0.32847142\n",
      "Epoch 69  train mse: 0.31937307\t valid mse:  0.34166263423761695ain mse: 0.33512703 69  train mse: 0.328902  train mse: 0.3300234 69  train mse: 0.3295902 69  train mse: 0.32668954 69  train mse: 0.32138002 69  train mse: 0.31804782\n",
      "Epoch 70  train mse: 0.31559634\t valid mse:  0.3370751596599595443 train mse: 0.30102843 70  train mse: 0.31372195 70  train mse: 0.31117162 70  train mse: 0.31519917\n",
      "Epoch 71  train mse: 0.32175428\t valid mse:  0.3385023459436526rain mse: 0.33289883 71  train mse: 0.31841466 71  train mse: 0.32192832 71  train mse: 0.322993960.32485735\n",
      "Epoch 72  train mse: 0.3010084\t valid mse:  0.3407520737323706rain mse: 0.30641437 72  train mse: 0.29690677 72  train mse: 0.30244455 72  train mse: 0.29538652 72  train mse: 0.30333847\n",
      "Epoch 73  train mse: 0.30225497\t valid mse:  0.33936348588126797ain mse: 0.314571 73  train mse: 0.31050554 73  train mse: 0.30598092 73  train mse: 0.30921674 73  train mse: 0.30037534\n",
      "Epoch 74  train mse: 0.32409784\t valid mse:  0.33458757812235795in mse: 0.3320359 74  train mse: 0.34271783 74  train mse: 0.3262941874  train mse: 0.3288487 74  train mse: 0.321824 74  train mse: 0.3237949\n",
      "Epoch 75  train mse: 0.29727647\t valid mse:  0.3395965819555791rain mse: 0.30801597 75  train mse: 0.30778563 75  train mse: 0.2988347\n",
      "Epoch 76  train mse: 0.31875193\t valid mse:  0.33175969382717924 0.30059028 76  train mse: 0.3183626 76  train mse: 0.31468207 76  train mse: 0.31061852\n",
      "Epoch 77  train mse: 0.3217293\t valid mse:  0.3409288895423385in mse: 0.33076330.32926103 77  train mse: 0.3247741 77  train mse: 0.3221162 77  train mse: 0.31998497\n",
      "Epoch 78  train mse: 0.33053908\t valid mse:  0.3424177209898452rain mse: 0.31316307 78  train mse: 0.304678878  train mse: 0.31046498 78  train mse: 0.32845807 78  train mse: 0.32742327 78  train mse: 0.3334574\n",
      "Epoch 79  train mse: 0.31609413\t valid mse:  0.3462914323828814ain mse: 0.3411827 79  train mse: 0.31629106 79  train mse: 0.3150753 0.31681097\n",
      "Epoch 80  train mse: 0.29503527\t valid mse:  0.34346374402955565ain mse: 0.3003757 80  train mse: 0.29890886 80  train mse: 0.29761046 80  train mse: 0.29391673  train mse: 0.2959427\n",
      "Epoch 81  train mse: 0.29798523\t valid mse:  0.33359931250462216ain mse: 0.2984691 81  train mse: 0.29871413 81  train mse: 0.2999804 81  train mse: 0.29714662 81  train mse: 0.29935166 81  train mse: 0.3004877 81  train mse: 0.29968134\n",
      "Epoch 82  train mse: 0.3246214\t valid mse:  0.3326780897701936train mse: 0.31017983  train mse: 0.32345974 82  train mse: 0.33440435 82  train mse: 0.3208977 82  train mse: 0.3243246\n",
      "Epoch 83  train mse: 0.31330732\t valid mse:  0.33336016930847695ain mse: 0.30846408 83  train mse: 0.31623194\n",
      "Epoch 84  train mse: 0.3177346\t valid mse:  0.336352244118800557083 84  train mse: 0.3156813 84  train mse: 0.30928585 84  train mse: 0.31687456 84  train mse: 0.314482\n",
      "Epoch 85  train mse: 0.3380439\t valid mse:  0.3432200920758737rain mse: 0.36350325 85  train mse: 0.35627806 85  train mse: 0.34641950.3477022 85  train mse: 0.34927747 85  train mse: 0.34669042 85  train mse: 0.34819397 85  train mse: 0.3415736 85  train mse: 0.33835053\n",
      "Epoch 86  train mse: 0.306977\t valid mse:  0.3340537786169741 train mse: 0.30797523 86  train mse: 0.30460265 86  train mse: 0.3027168 86  train mse: 0.30660316 86  train mse: 0.30516285\n",
      "Epoch 87  train mse: 0.31074643\t valid mse:  0.3482413874087165mse: 0.30357957 87  train mse: 0.30433774 87  train mse: 0.3027764 87  train mse: 0.30105170.30582455 87  train mse: 0.3099423\n",
      "Epoch 88  train mse: 0.29690427\t valid mse:  0.3341839488110566ain mse: 0.32261696 88  train mse: 0.30980074 88  train mse: 0.30131114 train mse: 0.3000794 88  train mse: 0.2978448 88  train mse: 0.29833207 88  train mse: 0.29746166\n",
      "Epoch 89  train mse: 0.30674857\t valid mse:  0.3326884968681969 mse: 0.294609670.30677846 89  train mse: 0.31215963 89  train mse: 0.31767702 89  train mse: 0.3108883 89  train mse: 0.31064796 89  train mse: 0.30740964\n",
      "Epoch 90  train mse: 0.3045544\t valid mse:  0.3348732977775145train mse: 0.31636176 90  train mse: 0.30924422 90  train mse: 0.31282872 90  train mse: 0.309188 90  train mse: 0.31374484 90  train mse: 0.30627412\n",
      "Epoch 91  train mse: 0.30950627\t valid mse:  0.3298856685702056\n",
      "Epoch 92  train mse: 0.3194639\t valid mse:  0.33155372455433024: 0.31374827 92  train mse: 0.32517412 92  train mse: 0.313154 92  train mse: 0.32088506 92  train mse: 0.32079977 92  train mse: 0.3152098  train mse: 0.314227\n",
      "Epoch 93  train mse: 0.29685333\t valid mse:  0.34414639879753534ain mse: 0.28025687 93  train mse: 0.2943088\n",
      "Epoch 94  train mse: 0.30254966\t valid mse:  0.33113402282135834 mse: 0.2952521 94  train mse: 0.29772666 94  train mse: 0.29649624 94  train mse: 0.30300018\n",
      "Epoch 95  train mse: 0.3156456\t valid mse:  0.3328317438392619train mse: 0.321208795  train mse: 0.33006305 95  train mse: 0.32146516 95  train mse: 0.3268189 train mse: 0.32253072 95  train mse: 0.3210397 95  train mse: 0.31667995\n",
      "Epoch 96  train mse: 0.2994125\t valid mse:  0.35385155091381526rain mse: 0.30500624 96  train mse: 0.30897215 96  train mse: 0.30765396 96  train mse: 0.30313605 train mse: 0.29935107  train mse: 0.29329455 96  train mse: 0.29839465\n",
      "Epoch 97  train mse: 0.30691493\t valid mse:  0.32925993349221366ain mse: 0.3063211 97  train mse: 0.30521655 97  train mse: 0.295717570.29081586 97  train mse: 0.3013017297  train mse: 0.3019089 97  train mse: 0.30726355\n",
      "Epoch 98  train mse: 0.30407014\t valid mse:  0.3370101773021548ain mse: 0.30154696\n",
      "Epoch 99  train mse: 0.31883463\t valid mse:  0.3371924697007597ain mse: 0.28849298 99  train mse: 0.31109416 99  train mse: 0.31533575 99  train mse: 0.3090615 99  train mse: 0.3134814 0.31621066 99  train mse: 0.31899068\n"
     ]
    }
   ],
   "source": [
    "# 1. batch 遍历训练集 metric\n",
    "#    1.1 自动求导\n",
    "# 2. epoch 结束 验证集 metric\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(xtrain_scaled) // batch_size\n",
    "optimizer = keras.optimizers.SGD()\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "\n",
    "def random_batch(x, y, batch_size=32):\n",
    "    idx = np.random.randint(0, len(x), size=batch_size)\n",
    "    return x[idx], y[idx]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=xtrain.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "# Relearn this!\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()\n",
    "    for step in range(steps_per_epoch):\n",
    "        x_batch, y_batch = random_batch(xtrain_scaled, ytrain,\n",
    "                                        batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            y_pred = tf.squeeze(y_pred, 1)\n",
    "            loss = keras.losses.mean_squared_error(y_batch, y_pred)\n",
    "            metric(y_batch, y_pred)\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        grads_and_vars = zip(grads, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        print(\"\\rEpoch\", epoch, \" train mse:\",\n",
    "              metric.result().numpy(), end=\"\")\n",
    "    y_valid_pred = model(xvalid_scaled)\n",
    "    y_valid_pred = tf.squeeze(y_valid_pred, 1)\n",
    "    valid_loss = keras.losses.mean_squared_error(y_valid_pred, yvalid)\n",
    "    print(\"\\t\", \"valid mse: \", valid_loss.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_py3",
   "language": "python",
   "name": "tf2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
