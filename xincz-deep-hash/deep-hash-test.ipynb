{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "illegal-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
      "tensorflow 2.4.0\n",
      "matplotlib 3.3.3\n",
      "numpy 1.19.5\n",
      "pandas 1.1.5\n",
      "sklearn 0.24.0\n",
      "tensorflow 2.4.0\n",
      "tensorflow.keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sklearn\n",
    "import PIL.Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (12, 12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in tf, mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "substantial-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-orientation",
   "metadata": {},
   "source": [
    "### Read image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loaded-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./datasets/cifar-10/train/1.png', 'frog'),\n",
      " ('./datasets/cifar-10/train/2.png', 'truck'),\n",
      " ('./datasets/cifar-10/train/3.png', 'truck'),\n",
      " ('./datasets/cifar-10/train/4.png', 'deer'),\n",
      " ('./datasets/cifar-10/train/5.png', 'automobile')]\n",
      "[('./datasets/cifar-10/test/1.png', 'cat'),\n",
      " ('./datasets/cifar-10/test/2.png', 'cat'),\n",
      " ('./datasets/cifar-10/test/3.png', 'cat'),\n",
      " ('./datasets/cifar-10/test/4.png', 'cat'),\n",
      " ('./datasets/cifar-10/test/5.png', 'cat')]\n",
      "Number of training examples: 50000\n",
      "Number of test examples: 300000\n"
     ]
    }
   ],
   "source": [
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "    'dog', 'frog', 'horse', 'ship', 'truck',\n",
    "]\n",
    "\n",
    "train_label_file = './datasets/cifar-10/trainLabels.csv'\n",
    "test_csv_file = './datasets/cifar-10/sampleSubmission.csv'\n",
    "train_folder = './datasets/cifar-10/train/'\n",
    "test_folder = './datasets/cifar-10/test/'\n",
    "\n",
    "def parse_csv_file(filepath, folder):\n",
    "    \"\"\"Parses csv files into (filename(path), label) format\"\"\"\n",
    "    results = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "    for line in lines:\n",
    "        image_id, label_str = line.strip('\\n').split(',')\n",
    "        image_full_path = os.path.join(folder, image_id + '.png')\n",
    "        results.append((image_full_path, label_str))\n",
    "    return results\n",
    "\n",
    "train_labels_info = parse_csv_file(train_label_file, train_folder)\n",
    "test_csv_info = parse_csv_file(test_csv_file, test_folder)\n",
    "\n",
    "pprint(train_labels_info[0:5])\n",
    "pprint(test_csv_info[0:5])\n",
    "print(\"Number of training examples: {}\".format(len(train_labels_info)))\n",
    "print(\"Number of test examples: {}\".format(len(test_csv_info)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "occupational-bible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          filepath       class\n",
      "0  ./datasets/cifar-10/train/1.png        frog\n",
      "1  ./datasets/cifar-10/train/2.png       truck\n",
      "2  ./datasets/cifar-10/train/3.png       truck\n",
      "3  ./datasets/cifar-10/train/4.png        deer\n",
      "4  ./datasets/cifar-10/train/5.png  automobile\n",
      "                              filepath       class\n",
      "0  ./datasets/cifar-10/train/45001.png       horse\n",
      "1  ./datasets/cifar-10/train/45002.png  automobile\n",
      "2  ./datasets/cifar-10/train/45003.png        deer\n",
      "3  ./datasets/cifar-10/train/45004.png  automobile\n",
      "4  ./datasets/cifar-10/train/45005.png    airplane\n",
      "                         filepath class\n",
      "0  ./datasets/cifar-10/test/1.png   cat\n",
      "1  ./datasets/cifar-10/test/2.png   cat\n",
      "2  ./datasets/cifar-10/test/3.png   cat\n",
      "3  ./datasets/cifar-10/test/4.png   cat\n",
      "4  ./datasets/cifar-10/test/5.png   cat\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_labels_info[0:45000])\n",
    "valid_df = pd.DataFrame(train_labels_info[45000:])\n",
    "test_df = pd.DataFrame(test_csv_info)\n",
    "\n",
    "train_df.columns = ['filepath', 'class']\n",
    "valid_df.columns = ['filepath', 'class']\n",
    "test_df.columns = ['filepath', 'class']\n",
    "\n",
    "print(train_df.head())\n",
    "print(valid_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-battery",
   "metadata": {},
   "source": [
    "### Construct ImageDataGenerator from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "flying-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45000 validated image filenames belonging to 10 classes.\n",
      "Found 5000 validated image filenames belonging to 10 classes.\n",
      "45000 5000\n"
     ]
    }
   ],
   "source": [
    "# Meta configuration\n",
    "height = 227\n",
    "width = 227\n",
    "channels = 3\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "\n",
    "# Flow from dataframe, not directory\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'wrap')\n",
    "# Takes the dataframe and the path to a directory and generates batches\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,            # Pandas dataframe containing filepaths relative to directory\n",
    "    directory = './',    # path to the directory to read images from\n",
    "    x_col = 'filepath',  # column in dataframe containing the filenames\n",
    "    y_col = 'class',     # column/s in dataframe that has the target data (labels)\n",
    "    classes = class_names,\n",
    "    target_size = (height, width),  # the dimensions to which all images found will be resized\n",
    "    batch_size = batch_size,        # size of the batches of data (default: 32)\n",
    "    seed = 7,            # random seed for shuffling and transformations\n",
    "    shuffle = True,\n",
    "    class_mode = 'sparse')\n",
    "\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    valid_df,\n",
    "    directory = './',\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'class',\n",
    "    classes = class_names,\n",
    "    target_size = (height, width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 7,\n",
    "    shuffle = False,\n",
    "    class_mode = \"sparse\")\n",
    "\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples\n",
    "print(train_num, valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "solved-swaziland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 227, 227, 3) (32,)\n",
      "[2. 1. 4. 4. 4. 4. 6. 5. 2. 8. 4. 6. 6. 3. 7. 1. 7. 2. 8. 8. 3. 0. 5. 3.\n",
      " 9. 1. 4. 5. 6. 7. 9. 2.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    x, y = train_generator.next()\n",
    "    print(x.shape, y.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-relation",
   "metadata": {},
   "source": [
    "### Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "varying-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Using AlexNet (slightly modified) structure\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=11, strides=(4, 4), padding=\"valid\",\n",
    "                        activation=\"selu\", input_shape=[width, height, channels]),\n",
    "    keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=5, strides=(1, 1), padding=\"same\",\n",
    "                        activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=3, strides=(1, 1), padding=\"same\",\n",
    "                        activation=\"selu\"),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=3, strides=(1, 1), padding=\"same\",\n",
    "                        activation=\"selu\"),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding=\"same\",\n",
    "                        activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation=\"selu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation=\"selu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1000, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-video",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hollow-aviation",
   "metadata": {},
   "source": [
    "### Triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "retained-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepHash.distance.tfversion import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "accredited-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(self, anchor, pos, neg, margin):\n",
    "    with tf.variable_scope('triplet_loss'):\n",
    "        pos_dist = distance(anchor, pos, pair=False, dist_type=\"euclidean2\")\n",
    "        neg_dist = distance(anchor, neg, pair=False, dist_type=\"euclidean2\")\n",
    "        basic_loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n",
    "        loss = tf.reduce_mean(basic_loss, 0)\n",
    "        \n",
    "        tf.summary.histogram('pos_dist', pos_dist)\n",
    "        tf.summary.histogram('neg_dist', neg_dist)\n",
    "        tf.summary.histogram('pos_dist - neg_dist', pos_dist - neg_dist)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "offensive-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_loss(self, z, h):\n",
    "    with tf.name_scope('quantization_loss'):\n",
    "        q_loss = tf.reduce_mean(tf.reduce_sum(tf.square(z - tf.matmul(h, self.C)), -1))\n",
    "    return q_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_quantization_loss(self, global_step):\n",
    "    anchor, pos, neg = tf.split(self.img_last_layer, 3, axis=0)\n",
    "    triplet_loss = triplet_loss(anchor, pos, neg, self.triplet_margin)\n",
    "    cq_loss = quantization_loss(self.img_last_layer, self.b_img)\n",
    "    self.loss = triplet_loss + cq_loss * self.cq_lambda\n",
    "    \n",
    "    lr = tf.train.exponential_decay(self.learning_rate,\n",
    "                                    global_step,\n",
    "                                    self.decay_step,\n",
    "                                    self.decay_factor,\n",
    "                                    staircase=True)\n",
    "    opt = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=0.9)\n",
    "    grads_and_vars = opt.compute_gradients(self.loss, self.train_layers+self.train_last_layer)\n",
    "    fcgrad, _ = grads_and_vars[-2]\n",
    "    fbgrad, _ = grads_and_vars[-1]\n",
    "    \n",
    "    tf.summary.scalar('loss', self.loss)\n",
    "    tf.summary.scalar('triplet_loss', triplet_loss)\n",
    "    tf.summary.scalar('cq_loss', cq_loss)\n",
    "    tf.summary.scalar('lr', self.lr)\n",
    "    self.merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-kingston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-bracelet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-dakota",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
